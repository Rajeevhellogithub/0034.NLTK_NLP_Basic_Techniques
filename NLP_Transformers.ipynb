{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completed in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZLETrjvv348",
    "outputId": "df15926a-dde2-416c-a77b-8b85ee824656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bF4xG51iwmeP"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cTbW0e-0w1Ez"
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "  tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TnuVVPD2w1Zn"
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, max_length=512):\n",
    "    tokens = tokenizer.encode(text, return_tensors='pt')[0]\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(0, len(tokens), max_length):\n",
    "        chunk = tokens[i:i + max_length]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3XrJlyfpxDfS"
   },
   "outputs": [],
   "source": [
    "def generate_responses(chunks):\n",
    "    responses = []\n",
    "    for chunk in chunks:\n",
    "        input_ids = chunk.unsqueeze(0)\n",
    "        output = model.generate(input_ids, pad_token_id=tokenizer.pad_token_id, max_length=100)\n",
    "        responses.append(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "GvM4GH8Sw1f8",
    "outputId": "de1921fd-022e-483a-d081-0487e70a68b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_text = \"Hello \" * 50\n",
    "long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNLToUEzw1jd",
    "outputId": "64e5c4d6-2c88-4f25-df06-700a5fd89fa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([15496, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435,\n",
       "         18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435,\n",
       "         18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435,\n",
       "         18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435,\n",
       "         18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435, 18435,\n",
       "           220])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = chunk_text(long_text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUOEVi5Fw1mj",
    "outputId": "877486b4-5d6d-4775-fdcb-0be0f53e1383"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = generate_responses(chunks)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LDSx25VDw1pm",
    "outputId": "8b5f8fba-ed89-4dcb-c17f-199c6caf9bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for chunk 1:\n",
      "Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~~ Hello ~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, response in enumerate(responses):\n",
    "    print(f\"Response for chunk {i+1}:\\n{response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
